{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUmH-e0B6G_8",
        "outputId": "cde87eb2-2ebf-43eb-c796-fd8ec9854e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjj0BM716Ivu",
        "outputId": "298d3cc6-29f7-4312-e652-089cea560823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1cNr3ZUNb8Sfe_VVxQeMcQFyojgSJ3xjc/Gaze_locking\n"
          ]
        }
      ],
      "source": [
        "cd ./drive/MyDrive/Gaze_locking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX8dCgBF6ZlO"
      },
      "outputs": [],
      "source": [
        "# !unzip columbia_gaze_data_set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1lv-uP8S7Lm"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "# import re\n",
        "\n",
        "# rootdir = './Columbia Gaze Data Set'\n",
        "# data = []\n",
        "# for subdir, dirs, files in os.walk(rootdir):\n",
        "#     for file in files:\n",
        "#         if 'jpg' in file.split('.'):\n",
        "#           filedata = file.split('_')\n",
        "#           temp = []\n",
        "#           temp.append(filedata[0])\n",
        "#           # print(filedata)\n",
        "#           temp.append(int(re.findall(r'-?\\d+',filedata[2])[0]))\n",
        "#           temp.append(int(re.findall(r'-?\\d+',filedata[3])[0]))\n",
        "#           temp.append(int(re.findall(r'-?\\d+',filedata[4])[0]))\n",
        "#           temp.append(os.path.join(subdir, file))\n",
        "#           if temp[2]==0 and temp[1]+temp[3]==0:\n",
        "#               temp.append(True)\n",
        "#           else:\n",
        "#               temp.append(False)\n",
        "\n",
        "#           # print(temp)\n",
        "#           # break\n",
        "#           data.append(temp)\n",
        "#           # print(os.path.join(subdir, file))\n",
        "\n",
        "# df = pd.DataFrame(data, columns=['person','pose','vertical','horizontal','path','is_gaze'])\n",
        "\n",
        "# df.to_csv('gaze_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdSQADzBgxN3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def detect_eyepatch(face_image):\n",
        "  gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
        "  x,y,w,h = faces[0]\n",
        "  roi_gray = gray[y:y+h, x:x+w]\n",
        "  roi_color = face_image[y:y+h, x:x+w]\n",
        "  eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "  eye_strip = []\n",
        "  for (ex,ey,ew,eh) in eyes[:2]:\n",
        "    mid_x = int(ex+ ew/2)\n",
        "    mid_y = int(ey + eh/2)\n",
        "    eye_strip.append(roi_gray[ey:ey+eh,ex:ex+ew])\n",
        "\n",
        "  #   cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
        "  # cv2_imshow(face_image)\n",
        "  return eye_strip\n",
        "\n",
        "# a = detect_eyepatch(cv2.imread('./Columbia Gaze Data Set/0001/0001_2m_-15P_-10V_5H.jpg'))\n",
        "  # cv2.rectangle(roi_color,(mid_x-24,mid_y-18),(mid_x+24,mid_y+18),(0,255,255),2)\n",
        "# cv2_imshow(face_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnCchZfZjXKX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "def getCorners(eye_patch):\n",
        "  corner1 = cv2.goodFeaturesToTrack(eye_patch[:,:12], 1, 0.01, 10)\n",
        "  corner2 = cv2.goodFeaturesToTrack(eye_patch[:,36:], 1, 0.01, 10)\n",
        "  corner1 = np.int0(corner1)\n",
        "  corner2 = np.int0(corner2)\n",
        "  corner1 = [corner1[0][0][0],corner1[0][0][1]]\n",
        "  corner2 = [corner2[0][0][0]+36,corner2[0][0][1]]\n",
        "  return [corner1,corner2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcQjW3uFmUAP"
      },
      "outputs": [],
      "source": [
        "def transform(eye_patch):\n",
        "  transformation_matrix=cv2.getPerspectiveTransform(np.float32([[0,0],[eye_patch.shape[1],0],[0,eye_patch.shape[0]],[eye_patch.shape[1],eye_patch.shape[0]]]),np.float32([\n",
        "          [0,0],\n",
        "          [48,0],\n",
        "          [0,36],\n",
        "          [48,36]\n",
        "      ]))\n",
        "  rectified_eye_patch = cv2.warpPerspective(eye_patch,transformation_matrix,(48,36),flags=cv2.INTER_LINEAR)\n",
        "  return rectified_eye_patch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HANRFAHJEAQo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def elliptical_mask(eye_patch,corners):\n",
        "  g_ell_center = ((corners[1][0]+corners[0][0])/2, (corners[0][1]+corners[1][1])/2)\n",
        "  g_ell_width = math.dist(corners[0],corners[1])\n",
        "  g_ell_height = g_ell_width/1.8\n",
        "\n",
        "  angle = np.rad2deg(np.arctan((corners[1][1]-corners[0][1])/(corners[1][0]-corners[0][0])))\n",
        "\n",
        "  g_ellipse = patches.Ellipse(g_ell_center, g_ell_width, g_ell_height, angle=angle, fill=False, edgecolor='green', linewidth=2)\n",
        "  cos_angle = np.cos(np.radians(180.-angle))\n",
        "  sin_angle = np.sin(np.radians(180.-angle))\n",
        "  x = np.array([[i for i in range(48)] for i in range(36)])\n",
        "  y = np.array([[j for i in range(48)]for j in range(36)])\n",
        "  xc = x - g_ell_center[0]\n",
        "  yc = y - g_ell_center[1]\n",
        "  xct = xc * cos_angle - yc * sin_angle\n",
        "  yct = xc * sin_angle + yc * cos_angle\n",
        "  rad_cc = (xct**2/(g_ell_width/2.)**2) + (yct**2/(g_ell_height/2.)**2)\n",
        "  eye_patch = np.where(rad_cc>1. , 0 , eye_patch)\n",
        "  return eye_patch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "TlM9cJE8HxnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "df = pd.read_csv('./gaze_data.csv')\n",
        "train_test_ratio = 0.9\n",
        "indexes = [ind for ind in df.index]\n",
        "random.shuffle(indexes)\n",
        "n = len(indexes)\n",
        "train = indexes[:int(train_test_ratio*n)]\n",
        "test = indexes[int(train_test_ratio*n):]\n",
        "\n",
        "with open('./feature_matrix.pkl','rb') as file:\n",
        "  feature_matrix = pkl.load(file)\n",
        "with open('./labels.pkl','rb') as file:\n",
        "  labels = pkl.load(file)\n",
        "\n",
        "with open('./hlabels.pkl','rb') as file:\n",
        "  hlabels = pkl.load(file)"
      ],
      "metadata": {
        "id": "JPejIibAHekV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the data"
      ],
      "metadata": {
        "id": "5fUwZFESHW7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mokYx5JUHRxY"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "# import random\n",
        "# import pickle\n",
        "# feature_matrix_t=[]\n",
        "# img_folder=os.listdir(\"./Columbia Gaze Data Set\")\n",
        "# # print(img_folder)\n",
        "# labels = []\n",
        "# df = pd.read_csv('./gaze_data.csv')\n",
        "\n",
        "# n = len(indexes)\n",
        "\n",
        "# print(len(train))\n",
        "# horizontal_labels=[]\n",
        "# for ind in train:\n",
        "#       # print(file)\n",
        "#       # if file.endswith('.jpg'):\n",
        "\n",
        "\n",
        "#     face_img = cv2.imread(df['path'][ind])\n",
        "#     try:\n",
        "#       eye_strip = detect_eyepatch(face_img)\n",
        "#       transformed_eye_strip = list(map(transform,eye_strip))\n",
        "#       corners = list(map(getCorners,transformed_eye_strip))\n",
        "#       masked_left_eye=elliptical_mask(transformed_eye_strip[0],corners[0])\n",
        "#       masked_right_eye=elliptical_mask(transformed_eye_strip[1],corners[1])\n",
        "#       final_eye_strip=np.hstack((masked_left_eye,masked_right_eye))\n",
        "#       #cv2_imshow(final_eye_strip)\n",
        "#       final_eye_strip=np.matrix.flatten(final_eye_strip)\n",
        "#       feature_matrix_t.append(final_eye_strip)\n",
        "#       labels.append(int(df['is_gaze'][ind]))\n",
        "#       horizontal_labels.append(int((int(df['horizontal'][ind])+15)/5))\n",
        "#       print(int((int(df['horizontal'][ind])+15)/5))\n",
        "#     except:\n",
        "#       continue\n",
        "#     #print(final_eye_strip.shape)\n",
        "# with open('feature_matrix.pkl', 'wb') as file:\n",
        "\n",
        "#     # A new file will be created\n",
        "#     pickle.dump(feature_matrix, file)\n",
        "\n",
        "# with open('labels.pkl', 'wb') as file:\n",
        "#   pickle.dump(labels, file)\n",
        "\n",
        "# with open('horizontal_labels.pkl', 'wb') as file:\n",
        "#   pickle.dump(horizontal_labels, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle as pkl\n",
        "\n",
        "def training_models(feature_matrix,labels,hlabels,da_model):\n",
        "  pca = PCA(n_components=200)\n",
        "  transformed_data = pca.fit_transform(normalize(feature_matrix,axis=1))\n",
        "  pred = []\n",
        "  # transformed_data = pca.fit_transform(feature_matrix,axis=1)\n",
        "  with open('pca_model.pkl', 'wb') as file:\n",
        "    pkl.dump(pca, file)\n",
        "  if da_model=='only_svm':\n",
        "    svm=SVC(kernel='rbf')\n",
        "    svm.fit(transformed_data,labels)\n",
        "    with open(f'svm_model_{da_model}.pkl', 'wb') as file:\n",
        "        # A new file will be created\n",
        "        pkl.dump(svm, file)\n",
        "    return\n",
        "\n",
        "  if da_model=='lda':\n",
        "    #LDA with assumption equal covariance matrices\n",
        "    clf = LinearDiscriminantAnalysis(n_components=6)\n",
        "    transformed_data_da=clf.fit_transform(transformed_data,hlabels)\n",
        "    # svm=LinearSVC()\n",
        "    svm=SVC(kernel='rbf')\n",
        "    svm.fit(transformed_data_da,labels)\n",
        "    pred = svm.predict(transformed_data_da)\n",
        "\n",
        "  if da_model=='qda':\n",
        "    clf = QuadraticDiscriminantAnalysis()\n",
        "    transformed_data_qda=clf.fit(transformed_data,hlabels)\n",
        "    # svm=LinearSVC()\n",
        "    svm=SVC(kernel='rbf')\n",
        "    svm.fit(transformed_data_qda.decision_function(transformed_data),labels)\n",
        "    pred = svm.predict(transformed_data_qda.decision_function(transformed_data))\n",
        "\n",
        "  if da_model=='mda':\n",
        "      n_classes = 7\n",
        "\n",
        "      # Create a pipeline with MDA\n",
        "      gmm = GaussianMixture(n_components=n_classes)\n",
        "      clf = LinearDiscriminantAnalysis()\n",
        "      # clf = make_pipeline(gmm, lda)\n",
        "\n",
        "      # Fit the pipeline to the data\n",
        "      # gmm.fit(transformed_data)\n",
        "      gmm_data = gmm.fit_predict(transformed_data)\n",
        "      transformed_data_da=clf.fit_transform(np.reshape(gmm_data,(gmm_data.shape[0],1)),hlabels)\n",
        "      with open(f'gmm.pkl','wb') as file:\n",
        "        pkl.dump(gmm, file)\n",
        "      svm=SVC(kernel='rbf',)\n",
        "      svm.fit(transformed_data_da,labels)\n",
        "      pred = svm.predict(transformed_data_da)\n",
        "\n",
        "  with open(f'{da_model}_model.pkl','wb') as file:\n",
        "    pkl.dump(clf, file)\n",
        "\n",
        "\n",
        "  with open(f'svm_model_{da_model}.pkl', 'wb') as file:\n",
        "\n",
        "    # A new file will be created\n",
        "    pkl.dump(svm, file)\n",
        "\n",
        "\n",
        "  return confusion_matrix(labels,pred)\n",
        "\n",
        "\n",
        "# training_models(feature_matrix,labels,hlabels,'lda')\n",
        "# training_models(feature_matrix,labels,hlabels,'qda')\n",
        "# training_models(feature_matrix,labels,hlabels,'mda')\n",
        "conf = training_models(feature_matrix,labels,hlabels,'only_svm')\n",
        "print(conf)"
      ],
      "metadata": {
        "id": "cC8NThDF_rlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "yFNLDFzYPJlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_pipeline(probe_img):\n",
        "  try:\n",
        "    predicted_label=[]\n",
        "    p_eye_strip = detect_eyepatch(probe_img)\n",
        "    p_transformed_eye_strip = list(map(transform,p_eye_strip))\n",
        "    p_corners = list(map(getCorners,p_transformed_eye_strip))\n",
        "\n",
        "    p_masked_left_eye=elliptical_mask(p_transformed_eye_strip[0],p_corners[0])\n",
        "    p_masked_right_eye=elliptical_mask(p_transformed_eye_strip[1],p_corners[1])\n",
        "    p_final_eye_strip=np.hstack((p_masked_left_eye,p_masked_right_eye))\n",
        "\n",
        "    with open('pca_model.pkl', 'rb') as file:\n",
        "\n",
        "        # Call load method to deserialze\n",
        "        pca = pkl.load(file)\n",
        "\n",
        "    p_pca=pca.transform(normalize(p_final_eye_strip.reshape(1,3456),axis=1))\n",
        "\n",
        "    with open('svm_model_only_svm.pkl','rb') as file:\n",
        "        svm = pkl.load(file)\n",
        "    predicted_label.append(svm.predict(p_pca))\n",
        "    # p_pca=pca.transform(p_final_eye_strip.reshape(1,3456),axis=1)\n",
        "    # if da_model=='lda':\n",
        "    with open('lda_model.pkl','rb') as file:\n",
        "      clf = pkl.load(file)\n",
        "    p_da=clf.transform(p_pca)\n",
        "    with open('svm_model_lda.pkl','rb') as file:\n",
        "      svm = pkl.load(file)\n",
        "    # predicted_label=svm.predict(p_da)\n",
        "    predicted_label.append(svm.predict(p_da))\n",
        "\n",
        "\n",
        "    # if da_model=='qda':\n",
        "    with open('qda_model.pkl','rb') as file:\n",
        "      clf = pkl.load(file)\n",
        "    p_da=clf.decision_function(p_pca)\n",
        "    with open('svm_model_qda.pkl','rb') as file:\n",
        "      svm = pkl.load(file)\n",
        "    # predicted_label=svm.predict(p_da)\n",
        "    predicted_label.append(svm.predict(p_da))\n",
        "\n",
        "\n",
        "    # if da_model=='mda':\n",
        "    with open('gmm.pkl','rb') as file:\n",
        "      gmm = pkl.load(file)\n",
        "    with open('mda_model.pkl','rb') as file:\n",
        "      clf = pkl.load(file)\n",
        "    gmm_data = gmm.predict(p_pca)\n",
        "    p_da=clf.transform(np.reshape(gmm_data,(gmm_data.shape[0],1)))\n",
        "    with open('svm_model_mda.pkl','rb') as file:\n",
        "      svm = pkl.load(file)\n",
        "    # predicted_label=svm.predict(p_da)\n",
        "    predicted_label.append(svm.predict(p_da))\n",
        "\n",
        "\n",
        "    return predicted_label\n",
        "  except:\n",
        "    return [-1,-1,-1,-1]\n",
        "# img = cv2.imread(df['path'][0])\n",
        "# a = test_pipeline(img,'mda')\n",
        "# print(a)\n",
        "\n",
        "tp = [0,0,0,0]\n",
        "fp = [0,0,0,0]\n",
        "fn = [0,0,0,0]\n",
        "tn = [0,0,0,0]\n",
        "for ind in test:\n",
        "  df = pd.read_csv('./gaze_data.csv')\n",
        "  label = int(df['is_gaze'][ind])\n",
        "  img = cv2.imread(df['path'][ind])\n",
        "  pred = []\n",
        "  pred=test_pipeline(img)\n",
        "  # pred.append(test_pipeline(img,'qda'))\n",
        "  # pred.append(test_pipeline(img,'mda'))\n",
        "\n",
        "  for i in range(4):\n",
        "    if pred[i]==-1:\n",
        "      continue\n",
        "    elif pred[i]==label:\n",
        "      if label==0:\n",
        "        tn[i]+=1\n",
        "      else:\n",
        "        tp[i]+=1\n",
        "    else:\n",
        "      if pred[i]==0:\n",
        "        fn[i]+=1\n",
        "      else:\n",
        "        fp[i]+=1\n"
      ],
      "metadata": {
        "id": "rdfKbev1PIDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "81a9446c-1864-4ff5-e8ae-0d99319b87c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-39df148c499e>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./gaze_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_gaze'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metrics\n",
        "precision = []\n",
        "recall = []\n",
        "accuracy = []\n",
        "specificity = []\n",
        "f1_score = []\n",
        "mcc = []\n",
        "\n",
        "# Calculate metrics for each set of values\n",
        "for i in range(len(tp)):\n",
        "    # Accuracy\n",
        "    acc = (tp[i] + tn[i]) / (tp[i] + tn[i] + fp[i] + fn[i])\n",
        "    accuracy.append(acc)\n",
        "\n",
        "    # Precision\n",
        "    prec = tp[i] / (tp[i] + fp[i]) if (tp[i] + fp[i]) > 0 else 0\n",
        "    precision.append(prec)\n",
        "\n",
        "    # Recall\n",
        "    rec = tp[i] / (tp[i] + fn[i]) if (tp[i] + fn[i]) > 0 else 0\n",
        "    recall.append(rec)\n",
        "\n",
        "    # Specificity\n",
        "    spec = tn[i] / (tn[i] + fp[i]) if (tn[i] + fp[i]) > 0 else 0\n",
        "    specificity.append(spec)\n",
        "\n",
        "    # F1 Score\n",
        "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
        "    f1_score.append(f1)\n",
        "\n",
        "    # Matthews Correlation Coefficient (MCC)\n",
        "    numerator = (tp[i] * tn[i]) - (fp[i] * fn[i])\n",
        "    denominator = ((tp[i] + fp[i]) * (tp[i] + fn[i]) * (tn[i] + fp[i]) * (tn[i] + fn[i])) ** 0.5\n",
        "    mcc_val = numerator / denominator if denominator != 0 else 0\n",
        "    mcc.append(mcc_val)\n",
        "\n",
        "# Print the calculated metrics\n",
        "for i in range(len(tp)):\n",
        "    print(f\"Set {i + 1} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy[i]:.4f}\")\n",
        "    print(f\"Precision: {precision[i]:.4f}\")\n",
        "    print(f\"Recall: {recall[i]:.4f}\")\n",
        "    print(f\"Specificity: {specificity[i]:.4f}\")\n",
        "    print(f\"F1 Score: {f1_score[i]:.4f}\")\n",
        "    print(f\"MCC: {mcc[i]:.4f}\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StntXsn8if7E",
        "outputId": "8ee7ac92-2283-4740-962c-c85e77257eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set 1 Metrics:\n",
            "Accuracy: 0.9473\n",
            "Precision: 0.2000\n",
            "Recall: 0.0800\n",
            "Specificity: 0.9858\n",
            "F1 Score: 0.1143\n",
            "MCC: 0.1027\n",
            "\n",
            "Set 2 Metrics:\n",
            "Accuracy: 0.9456\n",
            "Precision: 0.2667\n",
            "Recall: 0.1600\n",
            "Specificity: 0.9805\n",
            "F1 Score: 0.2000\n",
            "MCC: 0.1797\n",
            "\n",
            "Set 3 Metrics:\n",
            "Accuracy: 0.9422\n",
            "Precision: 0.2000\n",
            "Recall: 0.1200\n",
            "Specificity: 0.9787\n",
            "F1 Score: 0.1500\n",
            "MCC: 0.1263\n",
            "\n",
            "Set 4 Metrics:\n",
            "Accuracy: 0.9592\n",
            "Precision: 0.5333\n",
            "Recall: 0.3200\n",
            "Specificity: 0.9876\n",
            "F1 Score: 0.4000\n",
            "MCC: 0.3936\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}